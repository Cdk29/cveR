---
title: "flat_data_viz_cve.Rmd empty"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r development, include=FALSE}
library(testthat)
```

```{r development-load}
# Load already included functions if relevant
pkgload::load_all(export_all = FALSE)
```

# data_viz_cve

```{r}
library(doc2vec)
library(tokenizers.bpe)
library(udpipe)
# library(cveR)
library(stringr)
library(stopwords)

```


```{r}
#cves_harvesting()
#df <- read_data_CVEs("allitems.csv")
```


```{r function-filter_data}
#' Filter Data
#'
#' Filters a data frame based on specific conditions.
#'
#' @param df A data frame.
#' @return A filtered data frame.
#' @import dplyr
#' @importFrom stringr str_detect
#' @export
filter_data <- function(df) {
  data <- df %>%
    dplyr::filter(stringr::str_detect(Name, "CVE-2023")) %>%
    dplyr::filter(!stringr::str_detect(Description, "This candidate has been reserved"))
  return(data)
}
```

```{r}
# # Use function
# filtered_data <- filter_data(df)
# 
# # Check dimensions
# dim(filtered_data)
# 
# # Write data to CSV
# write.csv(filtered_data, "filtered_data_18_2023.csv", row.names = FALSE)
```

The line below solve a lot of problems with the encoding of the CVEs.
```{r}
df <- read.csv("filtered_data_18_2023.csv")
df$Description <- iconv(df$Description, from = "ISO-8859-1", to = "UTF-8")
```

```{r}
# Create a new dataframe
archived_cve <- data.frame(Name = df$Name,
                     Project = "new_cves",
                     Archived = "Yes")

# Check the new dataframe
# write.csv(archived_cve, "archived_data_18_2023.csv", row.names = FALSE)
```

```{r}
library(BTM)
library(udpipe)
```

```{r function-text_annotation}
#' @title Text Annotation
#' @description This function applies the udpipe model to a given dataframe and a specified text column for POS tagging.
#' @param df Dataframe containing the text data.
#' @param text_col Name of the column in df that contains the text data.
#' @param ud_model The udpipe model to use for POS tagging.
#' @return A data frame with annotations from the udpipe model.
#' @examples
#' data <- data.frame(description = c("text1", "text2", "text3"))
#' ud_model <- udpipe_load_model("english-ud-2.0-170801.udpipe")
#' annotated_data <- text_annotation(data, "description", ud_model)
#' @export
text_annotation <- function(df, text_col, ud_model) {
  # Apply the udpipe model to the text data
  ud_data <- udpipe_annotate(ud_model, x = df[[text_col]], tagger = "default", parser = "none")
  ud_data <- as.data.frame(ud_data)
  
  return(ud_data)
}
```

```{r}
# dl <- udpipe_download_model(language = "english")
ud_model <- udpipe_load_model("english-ewt-ud-2.5-191206.udpipe")

test_df <- head(df)
ud_data <- udpipe_annotate(ud_model, x = test_df$Description, tagger = "default", parser = "none")
ud_data <- as.data.frame(ud_data)
```

```{r}
test_df <- head(df, 600)
```

```{r examples-text_annotation}
u_df <- text_annotation(test_df, "Description", ud_model)
head(u_df)
```

```{r}
#' @title BTM Topic Modeling
#' @description This function applies the Biterm Topic Model (BTM) to a given annotated dataframe.
#' @param df Annotated dataframe containing the text data.
#' @param k Number of topics.
#' @param iter Number of iterations for the Gibbs sampling algorithm.
#' @return A BTM model.
#' @examples
#' data <- data.frame(doc_id = c(1,2,3), upos = c("NOUN", "PROPN", "NOUN"), lemma = c("noun1", "noun2", "noun3"))
#' model <- btm_topic_model(data, k = 5, iter = 1000)
btm_topic_model <- function(df, k = 10, iter = 1000) {
  
  
  # Filter the data to include only nouns (NN, NNP, NNS)
  # df <- subset(df, upos %in% c("PROPN", "VERB"))
  df <- subset(df, xpos %in% c("NN", "NNP", "NNS", "VB", "VBD", "VBG", "VBN", "VBP", "VBZ"))  
  # Prepare the data for the BTM model
  data <- df[, c("doc_id", "token")]

  # Apply the BTM model
  model <- BTM(data, k = k, iter = iter, background = TRUE)
  
  return(model)
}

```

```{r}
btm_model <- btm_topic_model(u_df)
```

```{r}
topicterms <- terms(btm_model, top_n = 10)
topicterms
```

```{r}
library(textplot)
library(ggraph)
library(concaveman)
plot(btm_model)
```

```{r}
library(data.table)
biterms <- as.data.table(u_df)
biterms <- biterms[, cooccurrence(x = token,
                                  relevant = xpos %in% c("NN", "NNP", "NNS", "VB", "VBD", "VBG", "VBN", "VBP", "VBZ") & 
                                             nchar(token) > 2 & !token %in% stopwords("en"),
                                  skipgram = 3),
                   by = list(doc_id)]
```

```{r}
traindata <- subset(u_df, xpos %in% c("NN", "NNP", "NNS", "VB", "VBD", "VBG", "VBN", "VBP", "VBZ") & !token %in% stopwords("en") & nchar(token) > 2)
traindata <- traindata[, c("doc_id", "token")]
model     <- BTM(traindata, biterms = biterms, k = 10, iter = 2000, background = TRUE)
```

```{r}
plot(model)
```


```{r function-btm_topic_model_cooccurrence}
#' @title BTM Topic Modeling with Cooccurrence
#' @description This function applies the Biterm Topic Model (BTM) to a given annotated dataframe,
#' using cooccurrence of terms to build the model.
#' @param df Annotated dataframe containing the text data.
#' @param k Number of topics.
#' @param iter Number of iterations for the Gibbs sampling algorithm.
#' @return A BTM model.
#' @examples
#' data <- data.frame(doc_id = c(1,2,3), xpos = c("NN", "VB", "NN"), token = c("token1", "token2", "token3"))
#' model <- btm_topic_model_cooccurrence(data, k = 5, iter = 1000)
#' @export
btm_topic_model_cooccurrence <- function(df, k = 10, iter = 2000) {

  # Extract cooccurrences of nouns, adjectives, and verbs within 3 words distance
  biterms <- as.data.table(df)
  biterms <- biterms[, cooccurrence(x = token,
                                    relevant = upos %in% c("PROPN", "ADJ", "VERB")  & 
                                               nchar(token) > 2 & !token %in% stopwords("en"),
                                    skipgram = 5),
                     by = list(doc_id)]
  
  # Build the biterm topic model
  # xpos %in% c("NN", "NNP", "NNS", "VB", "VBD", "VBG", "VBN", "VBP", "VBZ")
  traindata <- subset(df, upos %in% c("PROPN", "ADJ", "VERB")  & !token %in% stopwords("en") & nchar(token) > 2)
  traindata <- traindata[, c("doc_id", "token")]
  model <- BTM(traindata, biterms = biterms, k = k, iter = iter, background = TRUE)
  
  return(model)
}

```

```{r examples-btm_topic_model_cooccurrence}
library(stopwords)
# Read data from CSV
df <- read.csv("filtered_data_18_2023.csv")
df <- tail(df, 600)
df$Description <- iconv(df$Description, from = "ISO-8859-1", to = "UTF-8")
# Load the udpipe model
ud_model <- udpipe_load_model("english-ewt-ud-2.5-191206.udpipe")

# Annotate the text data
u_df <- text_annotation(df, "Description", ud_model)
# Run Biterm Topic Model with cooccurrence
btm_model_cooccurrence <- btm_topic_model_cooccurrence(u_df, k = 10)

# Plot the topic model
plot(btm_model_cooccurrence)


```

```{r}
# cveR::cves_harvesting()
archived_cve <- read.csv("archived_data_18_2023.csv")
```

```{r}
new_cves <- cveR::read_data_CVEs("allitems.csv")
new_cves <- filter_data(new_cves)
```

```{r function-update_cve}
#' @title Update the CVE dataframe
#'
#' @description Add the CVEs present in new_cves dataframe that are not yet present in archived_cve dataframe.
#' The new CVEs are added with the Project as 'new_cves' and Archived status as 'No'.
#'
#' @param new_cves Dataframe The dataframe with new CVEs.
#' @param archived_cve Dataframe The dataframe with archived CVEs.
#'
#' @return Dataframe The updated archived_cve dataframe with new CVEs added.
#' @export
#'
#' @examples
#' updated_cve <- update_cve(new_cves, archived_cve)

update_cve <- function(new_cves, archived_cve) {
  # Import necessary libraries
  
  # Find rows in new_cves not present in archived_cve
  new_entries <- anti_join(new_cves, archived_cve, by = "Name")

  # Select necessary columns and fill them with appropriate values
  new_entries <- new_entries %>%
    select(Name) %>%
    mutate(Project = "new_cves", Archived = "No")

  # Append new_entries to archived_cve
  updated_cve <- bind_rows(archived_cve, new_entries)
  
  return(updated_cve)
}

```

```{r examples-update_cve}
library(dplyr)
library(tidyverse)
archived_cve <- update_cve(new_cves, archived_cve)
```

```{r function-topic_model_btm}
#' @title Topic Modeling with Biterm Topic Model
#'
#' @description This function performs topic modeling on a given dataframe using Biterm Topic Model.
#' It first converts the text data in the 'Description' column from ISO-8859-1 to UTF-8,
#' and annotates it using the udpipe model. It then runs Biterm Topic Model with cooccurrence
#' and plots the resulting topic model.
#'
#' @param df Dataframe The input dataframe containing the text data.
#' @param ud_model_file String The file path to the udpipe model.
#'
#' @return A plot of the topic model.
#' @export
#'
#' @examples
#' df <- read.csv('path_to_your_file.csv')
#' ud_model_file <- "english-ewt-ud-2.5-191206.udpipe"
#' topic_model_plot <- topic_model_btm(df, ud_model_file)

topic_model_btm <- function(df, ud_model_file) {
  # Load necessary libraries
  # Convert text data from ISO-8859-1 to UTF-8
  df$Description <- iconv(df$Description, from = "ISO-8859-1", to = "UTF-8")

  # Load the udpipe model
  ud_model <- udpipe_load_model(ud_model_file)

  # Annotate the text data
  u_df <- text_annotation(df, "Description", ud_model)

  # Run Biterm Topic Model with cooccurrence
  btm_model_cooccurrence <- btm_topic_model_cooccurrence(u_df, k = 10)

  # Plot the topic model
  plot(btm_model_cooccurrence)
}

```

```{r}
df <- read.csv('path_to_your_file.csv')
ud_model_file <- "english-ewt-ud-2.5-191206.udpipe"
topic_model_plot <- topic_model_btm(df, ud_model_file)
```


```{r development-inflate, eval=FALSE}
# Run but keep eval=FALSE to avoid infinite loop
# Execute in the console directly
fusen::inflate(flat_file = "dev/flat_data_viz_cve.Rmd", vignette_name = "Data-viz")
```

